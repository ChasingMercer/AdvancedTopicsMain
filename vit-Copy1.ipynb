{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ee1f475-bf30-4384-bfe5-e93947c166c2",
   "metadata": {
    "id": "lVVgRws2wgT0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import random_split \n",
    "from transformers import ViTFeatureExtractor,  ViTForImageClassification,BeitImageProcessor, BeitForImageClassification\n",
    "from torch.utils.data import TensorDataset\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import evaluate\n",
    "import huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75afcc6-0e7e-47c4-bd31-db5cef23e87f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Initialise Cuda and check that Cuda is available\n",
    "# device = torch.device(\"cuda\")\n",
    "# print(device)\n",
    "# print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd68b99-2432-4c81-b43a-d5a9d8c06673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Set model path and create feature_extractor from pretrained Google Model\n",
    "# processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "# model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# model_name_or_path = 'google/vit-base-patch16'\n",
    "# feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5af7d681-007b-4127-aef8-9b5638603606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BeitForImageClassification.\n",
      "\n",
      "All the weights of BeitForImageClassification were initialized from the model checkpoint at microsoft/beit-base-patch16-224-pt22k-ft22k.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BeitForImageClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "processor = BeitImageProcessor.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')\n",
    "model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87df6b-7bbe-4108-8565-3fd00822a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "# download = torchvision.datasets.INaturalist(root='./', version='2021_valid', target_type='class', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84be2cd7-295d-4316-b021-65717b1b61c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eda4770b3dd438caa08dff3aeeb2b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/felixmorgan/.cache/huggingface/datasets/imagefolder/2021_valid-ed5e51059c21a180/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace5e5d7930e4e05856c35463b3f7043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load Dataset\n",
    "ds = load_dataset(path='./2021_valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ffc8dac-1bbe-4c5d-9acc-c903f468590c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# print(ds['train']['label'])\n",
    "\n",
    "print(len(set(ds['train']['label'])))\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd971e4-151c-4cb7-8096-5a59ce83edc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Open Json File used to remap annotation label to Class\n",
    "# with open('val.json') as json_file:\n",
    "#     json_data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fd100-e158-4dc8-a2a8-29deb2a00682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Iterates through Json File returning the new annotation of class for each index in dataset\n",
    "# cat_ids = list([i['category_id'] for i in json_data['annotations'][:]])\n",
    "\n",
    "# labels = []\n",
    "\n",
    "\n",
    "# for i in cat_ids:\n",
    "#     labels.append(json_data['categories'][i]['family'])\n",
    "    \n",
    "# # cat_labels = list([json_data['categories'][i]['class'] for i in cats_ids])\n",
    "# cats = pd.Series(labels, dtype='category').cat.codes\n",
    "# print(cats[0:10])\n",
    "# print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8c1a7-7062-4304-a3a4-1dfa197e8950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Remove old label and add new label then reshuffle dataset for sampling\n",
    "# ds['train'] = ds['train'].remove_columns('label')\n",
    "# ds['train'] = ds['train'].add_column(column=cats, name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0d2d3b0-07b7-43f7-b400-03502cf47634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/felixmorgan/.cache/huggingface/datasets/imagefolder/2021_valid-ed5e51059c21a180/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-a072699c1730d349.arrow\n"
     ]
    }
   ],
   "source": [
    "shuffled_ds = ds.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894335cc-87ad-474c-8854-8cce6ad4cf34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels = pd.Series(shuffled_ds['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51497c8c-eed3-46c2-9939-2ede79864ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc14e5-c4b6-4100-879d-9c2993e9f743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.bar(labels.unique(), labels.value_counts(), log=True)\n",
    "# print(labels.value_counts().mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d814c0-35a3-4b4b-9f39-406bae811504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = list(labels.value_counts().loc[lambda x : x>90].keys())\n",
    "# include_index = [i for i, j in enumerate(labels) if j in x]\n",
    "# include = [j for i, j in enumerate(labels) if j in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ae4d4-5664-4a61-af7e-f4e20f64f5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(set(x)))\n",
    "# print(set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1e516-d9d9-4786-a283-d3669f3c3d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def select_indexes(lst, lst_index):\n",
    "#     idx_dict = {}\n",
    "#     for i, val in enumerate(lst):\n",
    "#         if val not in idx_dict:\n",
    "#             idx_dict[val] = []\n",
    "#         elif len(idx_dict[val]) < 100:\n",
    "#             idx_dict[val].append(lst_index[i])\n",
    "#         elif all(len(v) == 100 for v in idx_dict.values()):\n",
    "#             break\n",
    "#     return idx_dict\n",
    "\n",
    "# sample = []\n",
    "# for key, value in select_indexes(include, include_index).items():\n",
    "#     print(key, len(value))\n",
    "#     sample += value\n",
    "\n",
    "# print(len(sample))\n",
    "# print(sample[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d01d5a-9718-4459-9592-5e002e96a6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7bcdc1e5-892b-4f03-9c5a-5dbce1813811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "model_ds = shuffled_ds\n",
    "print(model_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7e382-7ad6-4ea4-9e69-6b1384d61a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model_ds['label'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c797504-08b3-4e2d-81d4-021f94f49420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model_ds)\n",
    "# print(set(model_ds['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35487ce4-3da6-42de-9315-bf050fe2f310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_labels = pd.Series(model_ds['label']).astype('category').cat.codes\n",
    "\n",
    "# print(set(new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660eb6b-7bc6-436e-bb13-391942fdf0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_ds = model_ds.remove_columns('label')\n",
    "# model_ds = model_ds.add_column(column=new_labels, name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1078af05-6177-4cd7-a066-cea9be9360d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = feature_extractor([x for x in example_batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['label'] = example_batch['label']\n",
    "    return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96020f89-ad7c-4e49-8298-0157c4723dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ds = model_ds.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba3fc515-82f1-4ff8-abc8-67bad1826fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ds = model_ds['train'].train_test_split(test_size=0.2, shuffle=True)\n",
    "ds_valid = model_ds['test'].train_test_split(test_size=0.5)\n",
    "model_ds['valid'] = ds_valid['test']\n",
    "model_ds['test'] = ds_valid['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af816bc8-38cb-4b22-90ea-3b4ca051d06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0db7905b-8ef8-45c7-b8e9-7e1b1c865ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd2400-4138-43cd-9034-87f851591288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k', use_auth_token=access_token, num_labels=10000,ignore_mismatched_sizes=True)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbf2667f-f546-40df-bf13-f258ab0546e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#   output_dir=\"./vit-base\",\n",
    "#   per_device_train_batch_size=16,\n",
    "#   evaluation_strategy=\"steps\",\n",
    "#   num_train_epochs=4,\n",
    "#   fp16=False,\n",
    "#   save_steps=100,\n",
    "#   eval_steps=100,\n",
    "#   logging_steps=10,\n",
    "#   learning_rate=2e-4,\n",
    "#   save_total_limit=2,\n",
    "#   remove_unused_columns=False,\n",
    "#   push_to_hub=False,\n",
    "#   load_best_model_at_end=True,\n",
    "# )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./beit-base\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7611c36c-5fed-4eb9-9943-034dc21f431b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "access_token = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b73743af-3bbe-4c73-bf90-afc3ba8afa45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at /home/felixmorgan/.cache/huggingface/hub/models--microsoft--beit-base-patch16-224-pt22k-ft22k/snapshots/9da301148150e37e533abef672062fa49f6bda4f/preprocessor_config.json\n",
      "/home/felixmorgan/miniconda3/envs/pythonProject/lib/python3.9/site-packages/transformers/models/beit/feature_extraction_beit.py:28: FutureWarning: The class BeitFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use BeitImageProcessor instead.\n",
      "  warnings.warn(\n",
      "size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "crop_size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "Image processor BeitFeatureExtractor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"do_center_crop\": false,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_reduce_labels\": false,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"BeitFeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"BeitFeatureExtractor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k', use_auth_token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5667fbde-b25f-4ec9-882e-01b6176353f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1858c81fd9461384acf9a090e92141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "huggingface_hub.notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6b3bf524-4ce9-4a8c-a697-e7fcac3da449",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felixmorgan/PycharmProjects/pythonProject/./beit-base is already a clone of https://huggingface.co/ChasingMercer/beit-base. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=collate_fn,  \n",
    "#     compute_metrics=compute_metrics,\n",
    "#     train_dataset=model_ds[\"train\"],\n",
    "#     eval_dataset=model_ds[\"valid\"],\n",
    "#     tokenizer=feature_extractor\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=training_args,\n",
    "    train_dataset=model_ds[\"train\"],\n",
    "    eval_dataset=model_ds[\"valid\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517957b7-7d34-4507-992b-e3e76109dac0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felixmorgan/miniconda3/envs/pythonProject/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 80000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 7500\n",
      "  Number of trainable parameters = 93451984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1986' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1986/7500 1:02:03 < 2:52:27, 0.53 it/s, Epoch 0.79/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24939a-1082-4297-9b03-638c20d19c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = trainer.evaluate(model_ds['valid'])\n",
    "predictor = trainer.predict(model_ds['test'])\n",
    "\n",
    "predictions = [np.argmax(i) for i in predictor.predictions]\n",
    "print(evaluator)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "# trainer.log_metrics(\"train\", metrics)\n",
    "# trainer.save_metrics(\"train\", metrics)\n",
    "# trainer.save_metrics(\"eval\", metrics[\"eval_f1\", \"eval_accuracy\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
